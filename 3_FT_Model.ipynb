{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning with COCO Format\n",
    "\n",
    "We can now setup a script to finetune with pytorch lightning on top of standard coco format data.\n",
    "\n",
    "This is based upon the following example: https://colab.research.google.com/github/roboflow-ai/notebooks/blob/main/notebooks/train-huggingface-detr-on-custom-dataset.ipynb#scrollTo=qk6sRB0lueHY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U timm transformers supervision roboflow lightning mlflow pycocotools\n",
    "%pip install psutil pynvml \n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Configurations\n",
    "\n",
    "This will initialise all the variables that we need.\n",
    "\n",
    "We need to specify the Catalog / Schema for UC and we will use UC Volumes to store all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as pl\n",
    "from lightning.pytorch.loggers import MLFlowLogger\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "\n",
    "from transformers import DetrForObjectDetection, DetrImageProcessor\n",
    "\n",
    "import supervision as sv\n",
    "import os\n",
    "\n",
    "import mlflow\n",
    "\n",
    "ds_catalog = 'brian_ml_dev'\n",
    "ds_schame = 'image_processing'\n",
    "coco_volume = 'coco_dataset'\n",
    "save_dir = '/local_disk0/train'\n",
    "\n",
    "mlflow_experiment = '/Users/brian.law@databricks.com/brian_lightning'\n",
    "\n",
    "volume_path = f\"/Volumes/{ds_catalog}/{ds_schame}/{coco_volume}\"\n",
    "logging_volume_path = f\"/Volumes/{ds_catalog}/{ds_schame}/training\"\n",
    "image_path = f'{volume_path}'\n",
    "annotation_json = f'{volume_path}/annotations.json'\n",
    "\n",
    "CHECKPOINT = 'facebook/detr-resnet-50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the logging vol if necessary\n",
    "spark.sql(f\"CREATE VOLUME IF NOT EXISTS {ds_catalog}.{ds_schame}.training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Data Loader\n",
    "\n",
    "The first step is setting up the dataset and the dataloaders for our model training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CocoDetection(torchvision.datasets.CocoDetection):\n",
    "    \"\"\"\n",
    "    This dataset structures the input format to suit what we expect for the model\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        image_directory_path: str, \n",
    "        image_processor, \n",
    "        train: bool = True\n",
    "    ):\n",
    "        annotation_file_path = annotation_json\n",
    "        super(CocoDetection, self).__init__(image_directory_path, annotation_file_path)\n",
    "        self.image_processor = image_processor\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        images, annotations = super(CocoDetection, self).__getitem__(idx)        \n",
    "        image_id = self.ids[idx]\n",
    "        annotations = {'image_id': image_id, 'annotations': annotations}\n",
    "        encoding = self.image_processor(images=images, annotations=annotations, return_tensors=\"pt\")\n",
    "        pixel_values = encoding[\"pixel_values\"].squeeze()\n",
    "        target = encoding[\"labels\"][0]\n",
    "\n",
    "        return pixel_values, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_processor = DetrImageProcessor.from_pretrained(CHECKPOINT)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # DETR authors employ various image sizes during training, making it not possible \n",
    "    # to directly batch together images. Hence they pad the images to the biggest \n",
    "    # resolution in a given batch, and create a corresponding binary pixel_mask \n",
    "    # which indicates which pixels are real/which are padding\n",
    "    pixel_values = [item[0] for item in batch]\n",
    "    encoding = image_processor.pad(pixel_values, return_tensors=\"pt\")\n",
    "    labels = [item[1] for item in batch]\n",
    "    return {\n",
    "        'pixel_values': encoding['pixel_values'],\n",
    "        'pixel_mask': encoding['pixel_mask'],\n",
    "        'labels': labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the train and val dataloaders\n",
    "\n",
    "TRAIN_DATASET = CocoDetection(\n",
    "    image_directory_path=image_path, \n",
    "    image_processor=image_processor, \n",
    "    train=True)\n",
    "\n",
    "print(\"Number of training examples:\", len(TRAIN_DATASET))\n",
    "\n",
    "TRAIN_DATALOADER = DataLoader(dataset=TRAIN_DATASET, collate_fn=collate_fn, batch_size=4, shuffle=True)\n",
    "VAL_DATALOADER = DataLoader(dataset=TRAIN_DATASET, collate_fn=collate_fn, batch_size=4)\n",
    "\n",
    "categories = TRAIN_DATASET.coco.cats\n",
    "id2label = {k: v['name'] for k,v in categories.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Test out the batch loader\n",
    "for batch in TRAIN_DATALOADER:\n",
    "  print(batch)\n",
    "  break "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Lightning Model Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Detr(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, lr, lr_backbone, weight_decay):\n",
    "        super().__init__()\n",
    "        self.model = DetrForObjectDetection.from_pretrained(\n",
    "            pretrained_model_name_or_path=CHECKPOINT, \n",
    "            num_labels=len(id2label),\n",
    "            ignore_mismatched_sizes=True\n",
    "        )\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.lr_backbone = lr_backbone\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "    def forward(self, pixel_values, pixel_mask):\n",
    "        return self.model(pixel_values=pixel_values, pixel_mask=pixel_mask)\n",
    "\n",
    "    def common_step(self, batch, batch_idx):\n",
    "        pixel_values = batch[\"pixel_values\"]\n",
    "        pixel_mask = batch[\"pixel_mask\"]\n",
    "        labels = [{k: v.to(self.device) for k, v in t.items()} for t in batch[\"labels\"]]\n",
    "\n",
    "        outputs = self.model(pixel_values=pixel_values, pixel_mask=pixel_mask, labels=labels)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        loss_dict = outputs.loss_dict\n",
    "\n",
    "        return loss, loss_dict\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        #logger_module = self.logger.experiment\n",
    "        \n",
    "        loss, loss_dict = self.common_step(batch, batch_idx)     \n",
    "        # logs metrics for each training_step, and the average across the epoch\n",
    "        self.logger.log_metrics({\"training_loss\": loss}, batch_idx)\n",
    "        for k,v in loss_dict.items():\n",
    "            self.logger.log_metrics({\"train_\" + k: v.item()}, batch_idx)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        #logger_module = self.logger.experiment\n",
    "        loss, loss_dict = self.common_step(batch, batch_idx)     \n",
    "        self.logger.log_metrics({\"validation/loss\": loss}, batch_idx)\n",
    "        for k, v in loss_dict.items():\n",
    "            self.logger.log_metrics({\"validation_\" + k: v.item()}, batch_idx)\n",
    "            \n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # DETR authors decided to use different learning rate for backbone\n",
    "        # you can learn more about it here: \n",
    "        # - https://github.com/facebookresearch/detr/blob/3af9fa878e73b6894ce3596450a8d9b89d918ca9/main.py#L22-L23\n",
    "        # - https://github.com/facebookresearch/detr/blob/3af9fa878e73b6894ce3596450a8d9b89d918ca9/main.py#L131-L139\n",
    "        param_dicts = [\n",
    "            {\n",
    "                \"params\": [p for n, p in self.named_parameters() if \"backbone\" not in n and p.requires_grad]},\n",
    "            {\n",
    "                \"params\": [p for n, p in self.named_parameters() if \"backbone\" in n and p.requires_grad],\n",
    "                \"lr\": self.lr_backbone,\n",
    "            },\n",
    "        ]\n",
    "        return torch.optim.AdamW(param_dicts, lr=self.lr, weight_decay=self.weight_decay)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return TRAIN_DATALOADER\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return VAL_DATALOADER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop - Single GPU in notebook\n",
    "\n",
    "We will start with single gpu in the notebook.\n",
    "Once we scale we will need to change the way that we approach this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "MAX_EPOCHS = 10\n",
    "\n",
    "model = Detr(lr=1e-4, lr_backbone=1e-5, weight_decay=1e-4)\n",
    "\n",
    "# it is best to set it here\n",
    "## Otherwise it seems glitchy\n",
    "mlflow.set_experiment(mlflow_experiment)\n",
    "\n",
    "#os.environ['MLFLOW_EXPERIMENT_NAME'] = mlflow_experimentz\n",
    "os.environ['MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING'] = 'true'\n",
    "\n",
    "# we need to start the logger here as it creates a new run\n",
    "with mlflow.start_run(log_system_metrics=True, run_name='training_test') as run:\n",
    "\n",
    "    # this will log our training hyuperparams\n",
    "    mlflow.pytorch.autolog()\n",
    "\n",
    "    mlf_logger = MLFlowLogger(\n",
    "        #experiment_name=mlflow_experiment,\n",
    "        tracking_uri=\"databricks\",\n",
    "        checkpoint_path_prefix=\"brian_testing\",\n",
    "        run_id=run.info.run_id\n",
    "    )\n",
    "\n",
    "# we need to see why this gets logged to the wrong experiment\n",
    "# MLFLOW_SYSTEM_METRICS_NODE_ID - use this one for setting different node prefixes for distributed\n",
    "\n",
    "# pytorch_lightning < 2.0.0\n",
    "# trainer = Trainer(gpus=1, max_epochs=MAX_EPOCHS, gradient_clip_val=0.1, accumulate_grad_batches=8, log_every_n_steps=5)\n",
    "\n",
    "# pytorch_lightning >= 2.0.0\n",
    "    trainer = pl.Trainer(devices=1, accelerator=\"gpu\", max_epochs=MAX_EPOCHS, \n",
    "                     gradient_clip_val=0.1, accumulate_grad_batches=8, log_every_n_steps=5,\n",
    "                     logger=mlf_logger)\n",
    "\n",
    "    trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving to TorchDistributor\n",
    "\n",
    "In order to distribute effectively across databricks, we will use TorchDistributor\n",
    "\n",
    "As that results in our code running in separate python threads, we need to setup credentials in order to make sure that we can communicate back with mlflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.torch.distributor import TorchDistributor\n",
    "\n",
    "### Setup of MLFlow variables\n",
    "\n",
    "### distributed mlflow configs - we need to manually set the login creds\n",
    "browser_host = spark.conf.get(\"spark.databricks.workspaceUrl\")\n",
    "db_host = f\"https://{browser_host}\"\n",
    "db_token = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop - Multi GPU Single Node\n",
    "\n",
    "When we go to multi gpu with lightning, we need to move to torch distributor\n",
    "(This will be different per framework ie HuggingFace native can do in notebook multi-gpu okay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpus_per_node = 2\n",
    "num_nodes = 1\n",
    "num_processes = num_gpus_per_node * num_nodes\n",
    "local_status = True if num_nodes == 1 else False\n",
    "\n",
    "MAX_EPOCHS = 3\n",
    "\n",
    "def training_function(total_gpus: int):\n",
    "    \n",
    "    # we need to set the mlflow vars here due to glitches with os environ\n",
    "    os.environ['MLFLOW_TRACKING_URI'] = 'databricks'\n",
    "    os.environ['DATABRICKS_HOST'] = db_host\n",
    "    os.environ['DATABRICKS_TOKEN'] = db_token\n",
    "    \n",
    "    mlflow.set_experiment(mlflow_experiment)\n",
    "    \n",
    "    model = Detr(lr=1e-4, lr_backbone=1e-5, weight_decay=1e-4)\n",
    "    \n",
    "    rank = int(os.environ.get(\"RANK\", 0))\n",
    "\n",
    "    if rank == 0:\n",
    "        with mlflow.start_run(log_system_metrics=True, run_name='training_test') as run:\n",
    "\n",
    "            # this will log our training hyuperparams\n",
    "            mlflow.pytorch.autolog()\n",
    "\n",
    "            mlf_logger = MLFlowLogger(\n",
    "            #experiment_name=mlflow_experiment,\n",
    "                tracking_uri=\"databricks\",\n",
    "                run_id=run.info.run_id,\n",
    "                save_dir=f'{logging_volume_path}',\n",
    "                checkpoint_path_prefix=f'{logging_volume_path}/checkpoints'\n",
    "            )\n",
    "            \n",
    "            # note the addition of strategy here\n",
    "            trainer = pl.Trainer(default_root_dir=f'{volume_path}/training',\n",
    "                                 devices=total_gpus, accelerator=\"gpu\", max_epochs=MAX_EPOCHS, \n",
    "                        gradient_clip_val=0.1, accumulate_grad_batches=8, log_every_n_steps=5,\n",
    "                        logger=mlf_logger, strategy='ddp')\n",
    "\n",
    "            trainer.fit(model)\n",
    "    else:\n",
    "        mlf_logger = None\n",
    "        \n",
    "        # note the addition of strategy here\n",
    "        trainer = pl.Trainer(default_root_dir=f'{volume_path}/training',\n",
    "                             devices=total_gpus, accelerator=\"gpu\", max_epochs=MAX_EPOCHS, \n",
    "                        gradient_clip_val=0.1, accumulate_grad_batches=8, log_every_n_steps=5,\n",
    "                        logger=mlf_logger, strategy='ddp')\n",
    "\n",
    "        trainer.fit(model)\n",
    "        \n",
    "    return trainer\n",
    "    \n",
    "\n",
    "distributor = TorchDistributor(num_processes=num_processes, \n",
    "                               local_mode=local_status, use_gpu=True)\n",
    "\n",
    "train_obj = distributor.run(training_function, num_processes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Cluster Training Job\n",
    "\n",
    "In order to train on a cluster we will need to package up the code even more.\n",
    "\n",
    "This becomes a bit hard to follow within the notebook format so although we could keep it within the notebook it'll be easier to package it up into a training script. This will also make it easier to transfomer to our newer model training product that is currently under development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pyspark.ml.torch.distributor import TorchDistributor\n",
    "\n",
    "from mlflow.data.uc_volume_dataset_source import UCVolumeDatasetSource\n",
    "from mlflow.data.dataset import Dataset\n",
    "from mlflow.data import load_delta\n",
    "\n",
    "num_gpus_per_node = 2\n",
    "num_nodes = 2\n",
    "num_processes = num_gpus_per_node * num_nodes\n",
    "local_status = True if num_nodes == 1 else False\n",
    "\n",
    "source_data = spark.sql(f\"SELECT * FROM {ds_catalog}.{ds_schame}.gold_detr_results_training_frame\")\n",
    "### Test out multi-node training\n",
    "\n",
    "mlflow.set_experiment(mlflow_experiment)\n",
    "\n",
    "with mlflow.start_run(run_name='multi-node') as run:\n",
    "  \n",
    "  source_table = load_delta(\n",
    "    table_name=f'{ds_catalog}.{ds_schame}.silver_detr_results_w_frame',\n",
    "    name = \"run_source_data\"\n",
    "  )\n",
    "  \n",
    "  dataset = UCVolumeDatasetSource(path=f'{volume_path}')\n",
    "  #digest = compute_folder_digest(volume_path)\n",
    "\n",
    "  #source_table = Dataset(source=source_table, name=\"train_source_table\")\n",
    "  # digest is a uuid type keycode to identify a dataset usually the first few char of some hash \n",
    "  \n",
    "  cache_train = Dataset(source=dataset, name=\"train_dataset\", digest='abc')\n",
    "  cache_val = Dataset(source=dataset, name=\"val_dataset\", digest='abc')\n",
    "\n",
    "  mlflow.log_input(source_table, context=\"upstream_table\")\n",
    "  mlflow.log_input(cache_train, context=\"train_dataset\")\n",
    "  mlflow.log_input(cache_val, context=\"val_dataset\")\n",
    "\n",
    "  distributor = TorchDistributor(num_processes=num_processes, \n",
    "                               local_mode=local_status, use_gpu=True)\n",
    "\n",
    "  entry_dict = {'batch_size': num_processes*3,\n",
    "              'max_epochs':2,\n",
    "              'total_gpus': num_processes,\n",
    "              'host': db_host,\n",
    "              'token': db_token,\n",
    "              'run_id': run.info.run_id,\n",
    "              'uc_catalog': ds_catalog,\n",
    "              'uc_schema': ds_schame,\n",
    "              'mlflow_experiment': mlflow_experiment}\n",
    "\n",
    "  train_obj = distributor.run('scripts/tune_model.py', json.dumps(entry_dict))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
