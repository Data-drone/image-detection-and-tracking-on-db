{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# YOLO Hyperparameter Tuning Job\n",
        "\n",
        "This notebook creates a Databricks job to run the YOLO multi-GPU training notebook with hyperparameter optimization using Optuna.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parameters\n",
        "\n",
        "Define job configuration parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -U databricks-sdk optuna\n",
        "%restart_python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "job_name = \"finetune_yolo_job\"\n",
        "notebook_path = \"/Workspace/Users/brian.law@databricks.com/.bundle/image-detection-and-tracking-on-db/dev/files/advanced_examples/finetune_ultralytics_yolo_multi_gpu\"\n",
        "init_script_path = \"/Workspace/Users/brian.law@databricks.com/.bundle/image-detection-and-tracking-on-db/dev/files/scripts/init_script_ultralytics.sh\"\n",
        "max_concurrent_runs = 2\n",
        "\n",
        "# Metrics output location (must match notebook's logging_vol_path)\n",
        "metrics_volume_path = \"/Volumes/brian_ml_dev/image_processing/training\"\n",
        "\n",
        "# Cluster configuration\n",
        "spark_version = \"17.3.x-scala2.13\"  # MLR 17.3 LTS\n",
        "node_type = \"Standard_NC48ads_A100_v4\"  # Azure NC48ads with 2x A100 GPUs\n",
        "\n",
        "print(f\"Job Configuration:\")\n",
        "print(f\"  Job Name: {job_name}\")\n",
        "print(f\"  Notebook: {notebook_path}\")\n",
        "print(f\"  Init Script: {init_script_path}\")\n",
        "print(f\"  Runtime: {spark_version}\")\n",
        "print(f\"  Node Type: {node_type}\")\n",
        "print(f\"  Max Concurrent Runs: {max_concurrent_runs}\")\n",
        "print(f\"  Metrics Path: {metrics_volume_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Required Libraries\n",
        "\n",
        "Load the Databricks SDK for job management.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from databricks.sdk import WorkspaceClient\n",
        "from databricks.sdk.service import jobs, compute\n",
        "from databricks.sdk.service.compute import Kind\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize Workspace Client\n",
        "\n",
        "Create a client to interact with the Databricks workspace.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "w = WorkspaceClient()\n",
        "print(\"Workspace client initialized\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Check if Job Already Exists\n",
        "\n",
        "Search for existing jobs with the same name.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "existing_jobs = w.jobs.list(name=job_name)\n",
        "existing_job = None\n",
        "\n",
        "for job in existing_jobs:\n",
        "    if job.settings.name == job_name:\n",
        "        existing_job = job\n",
        "        break\n",
        "\n",
        "if existing_job:\n",
        "    print(f\"Job '{job_name}' already exists with ID: {existing_job.job_id}\")\n",
        "else:\n",
        "    print(f\"Job '{job_name}' does not exist\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Job if Not Exists\n",
        "\n",
        "Create the job configuration with notebook task and parallelism settings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not existing_job:\n",
        "    # Default parameters matching YOLO multi-GPU notebook\n",
        "    base_parameters = {\n",
        "        \"epochs\": \"2\",\n",
        "        \"batch_size\": \"128\",\n",
        "        \"img_size\": \"640\",\n",
        "        \"initial_lr\": \"0.005\",\n",
        "        \"final_lr\": \"0.1\",\n",
        "        \"device_config\": \"[0,1]\",\n",
        "        \"run_name\": \"multi_gpu_run\"\n",
        "    }\n",
        "    \n",
        "    # Cluster configuration for YOLO training\n",
        "    cluster_config = compute.ClusterSpec(\n",
        "        spark_version=spark_version,\n",
        "        node_type_id=node_type,\n",
        "        num_workers=0,  # Single-node cluster (driver-only)\n",
        "        driver_node_type_id=node_type,\n",
        "        data_security_mode=DataSecurityMode.SINGLE_USER,\n",
        "        kind=Kind.CLASSIC_PREVIEW,\n",
        "        use_ml_runtime=True,\n",
        "        spark_conf={\n",
        "            \"spark.databricks.cluster.profile\": \"singleNode\",\n",
        "            \"spark.master\": \"local[*, 4]\"\n",
        "        },\n",
        "        custom_tags={\n",
        "            \"ResourceClass\": \"SingleNode\"\n",
        "        },\n",
        "        init_scripts=[\n",
        "            compute.InitScriptInfo(\n",
        "                workspace=compute.WorkspaceStorageInfo(\n",
        "                    destination=init_script_path\n",
        "                )\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    created_job = w.jobs.create(\n",
        "        name=job_name,\n",
        "        tasks=[\n",
        "            jobs.Task(\n",
        "                task_key=\"finetune_task\",\n",
        "                notebook_task=jobs.NotebookTask(\n",
        "                    notebook_path=notebook_path,\n",
        "                    source=jobs.Source.WORKSPACE,\n",
        "                    base_parameters=base_parameters\n",
        "                ),\n",
        "                new_cluster=cluster_config\n",
        "            )\n",
        "        ],\n",
        "        max_concurrent_runs=max_concurrent_runs\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nâœ… Job '{job_name}' created successfully\")\n",
        "    print(f\"Job ID: {created_job.job_id}\")\n",
        "    print(f\"Max concurrent runs: {max_concurrent_runs}\")\n",
        "    print(f\"\\nCluster Configuration:\")\n",
        "    print(f\"  Runtime: {spark_version}\")\n",
        "    print(f\"  Node Type: {node_type}\")\n",
        "    print(f\"  Workers: 0 (Single Node)\")\n",
        "    print(f\"  Init Script: {init_script_path.split('/')[-1]}\")\n",
        "    print(f\"\\nDefault parameters:\")\n",
        "    for key, value in base_parameters.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "else:\n",
        "    print(f\"Job '{job_name}' already exists, skipping creation\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Display Job Details\n",
        "\n",
        "Show the job configuration details.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_job = existing_job if existing_job else w.jobs.get(created_job.job_id)\n",
        "\n",
        "print(f\"\\nJob Configuration:\")\n",
        "print(f\"  Name: {final_job.settings.name}\")\n",
        "print(f\"  Job ID: {final_job.job_id}\")\n",
        "print(f\"  Max Concurrent Runs: {final_job.settings.max_concurrent_runs}\")\n",
        "print(f\"  Notebook Path: {final_job.settings.tasks[0].notebook_task.notebook_path}\")\n",
        "\n",
        "# Display cluster configuration\n",
        "task = final_job.settings.tasks[0]\n",
        "if task.new_cluster:\n",
        "    print(f\"\\nCluster Configuration:\")\n",
        "    print(f\"  Spark Version: {task.new_cluster.spark_version}\")\n",
        "    print(f\"  Node Type: {task.new_cluster.node_type_id}\")\n",
        "    print(f\"  Workers: {task.new_cluster.num_workers}\")\n",
        "    if task.new_cluster.init_scripts:\n",
        "        print(f\"  Init Scripts: {len(task.new_cluster.init_scripts)} configured\")\n",
        "\n",
        "if task.notebook_task.base_parameters:\n",
        "    print(f\"\\nDefault Parameters:\")\n",
        "    for key, value in task.notebook_task.base_parameters.items():\n",
        "        print(f\"  {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Trigger Job Run\n",
        "\n",
        "Start a new run of the job.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "job_id = final_job.job_id\n",
        "\n",
        "# Default YOLO parameters for test run\n",
        "test_params = {\n",
        "    \"epochs\": \"2\",\n",
        "    \"batch_size\": \"128\",\n",
        "    \"img_size\": \"640\",\n",
        "    \"initial_lr\": \"0.005\",\n",
        "    \"final_lr\": \"0.1\",\n",
        "    \"device_config\": \"[0,1]\",\n",
        "    \"run_name\": \"test_run\"\n",
        "}\n",
        "\n",
        "run = w.jobs.run_now(\n",
        "    job_id=job_id,\n",
        "    notebook_params=test_params\n",
        ")\n",
        "\n",
        "print(f\"\\nJob run triggered successfully\")\n",
        "print(f\"Run ID: {run.run_id}\")\n",
        "print(f\"Parameters:\")\n",
        "for key, value in test_params.items():\n",
        "    print(f\"  {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Monitor Run Status\n",
        "\n",
        "Check the status of the triggered run.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "import json\n",
        "from databricks.sdk.service.jobs import RunLifeCycleState\n",
        "\n",
        "print(f\"Monitoring run {run.run_id}...\")\n",
        "print(f\"Status updates:\")\n",
        "\n",
        "while True:\n",
        "    run_status = w.jobs.get_run(run.run_id)\n",
        "    state = run_status.state.life_cycle_state\n",
        "    \n",
        "    print(f\"  {state}\")\n",
        "    \n",
        "    if state in [RunLifeCycleState.TERMINATED, RunLifeCycleState.SKIPPED, RunLifeCycleState.INTERNAL_ERROR]:\n",
        "        result_state = run_status.state.result_state\n",
        "        print(f\"\\nFinal State: {result_state}\")\n",
        "        \n",
        "        try:\n",
        "            if run_status.tasks and len(run_status.tasks) > 0:\n",
        "                task_run_id = run_status.tasks[0].run_id\n",
        "                print(f\"Retrieving output from task run: {task_run_id}\")\n",
        "                \n",
        "                run_output = w.jobs.get_run_output(task_run_id)\n",
        "                if run_output.notebook_output and run_output.notebook_output.result:\n",
        "                    print(f\"\\nNotebook Output:\")\n",
        "                    metrics = json.loads(run_output.notebook_output.result)\n",
        "                    print(json.dumps(metrics, indent=2))\n",
        "        except Exception as e:\n",
        "            print(f\"\\nCould not retrieve notebook output: {e}\")\n",
        "        \n",
        "        break\n",
        "    \n",
        "    time.sleep(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hyperparameter Optimization with Optuna\n",
        "\n",
        "Use Optuna to find the optimal YOLO hyperparameters (batch size, learning rates) by running multiple training experiments in parallel.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install and Import Optuna\n",
        "\n",
        "Set up Optuna for hyperparameter optimization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import optuna\n",
        "\n",
        "print(f\"Optuna version: {optuna.__version__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Objective Function\n",
        "\n",
        "Create a function that runs a training job with different hyperparameters and returns the metric to optimize.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# job_id = 281960318776979\n",
        "\n",
        "def objective(trial):\n",
        "    import time\n",
        "    import json\n",
        "    \n",
        "    # Sample YOLO hyperparameters\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n",
        "    initial_lr = trial.suggest_float(\"initial_lr\", 0.001, 0.01, log=True)\n",
        "    final_lr = trial.suggest_float(\"final_lr\", 0.01, 0.5)\n",
        "    \n",
        "    # Fixed parameters for faster experimentation\n",
        "    epochs = 25  # Adjust based on your needs\n",
        "    img_size = 640\n",
        "    device_config = \"[0,1]\"\n",
        "    run_name = f\"trial_{trial.number}\"\n",
        "    \n",
        "    print(f\"\\nTrial {trial.number}:\")\n",
        "    print(f\"  batch_size={batch_size}, initial_lr={initial_lr:.5f}, final_lr={final_lr:.3f}\")\n",
        "    \n",
        "    # Prepare parameters matching the multi-GPU notebook widgets\n",
        "    params = {\n",
        "        \"epochs\": str(epochs),\n",
        "        \"batch_size\": str(batch_size),\n",
        "        \"img_size\": str(img_size),\n",
        "        \"initial_lr\": str(initial_lr),\n",
        "        \"final_lr\": str(final_lr),\n",
        "        \"device_config\": device_config,\n",
        "        \"run_name\": run_name\n",
        "    }\n",
        "    \n",
        "    # Trigger job run\n",
        "    run = w.jobs.run_now(\n",
        "        job_id=job_id,\n",
        "        notebook_params=params\n",
        "    )\n",
        "    \n",
        "    job_run_id = run.run_id\n",
        "    print(f\"  Job Run ID: {job_run_id}\")\n",
        "    print(f\"  Metrics file: {metrics_volume_path}/metrics_{job_run_id}.json\")\n",
        "    \n",
        "    # Wait for job completion\n",
        "    while True:\n",
        "        run_status = w.jobs.get_run(job_run_id)\n",
        "        state = run_status.state.life_cycle_state\n",
        "        \n",
        "        if state in [RunLifeCycleState.TERMINATED, RunLifeCycleState.SKIPPED, RunLifeCycleState.INTERNAL_ERROR]:\n",
        "            result_state = run_status.state.result_state\n",
        "            print(f\"  Run completed: {result_state}\")\n",
        "            \n",
        "            if result_state != jobs.RunResultState.SUCCESS:\n",
        "                print(f\"  Trial failed with state: {result_state}\")\n",
        "                raise optuna.TrialPruned()\n",
        "            \n",
        "            # Read metrics from saved JSON file\n",
        "            try:\n",
        "                time.sleep(5)  # Brief delay to ensure file is written\n",
        "                \n",
        "                metrics_file = f\"{metrics_volume_path}/metrics_{job_run_id}.json\"\n",
        "                print(f\"  Reading metrics from: {metrics_file}\")\n",
        "                \n",
        "                with open(metrics_file, 'r') as f:\n",
        "                    metrics = json.load(f)\n",
        "                \n",
        "                val_map = metrics.get(\"val_mAP50\", 0.0)\n",
        "                print(f\"  Validation mAP@50: {val_map:.4f}\")\n",
        "                \n",
        "                # Return val_mAP50 for maximization\n",
        "                return val_map\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"  Error reading metrics file: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "                raise optuna.TrialPruned()\n",
        "            \n",
        "            break\n",
        "        \n",
        "        time.sleep(30)  # Check every 30 seconds (YOLO training takes time)\n",
        "    \n",
        "    raise optuna.TrialPruned()\n",
        "\n",
        "print(\"Objective function defined for YOLO hyperparameter optimization\")\n",
        "print(f\"Metrics will be read from: {metrics_volume_path}/metrics_<run_id>.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run Optimization Study\n",
        "\n",
        "Execute Optuna study to find the best n_estimators value.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "study = optuna.create_study(\n",
        "    direction=\"maximize\",  # Maximize mAP (we return negative, so minimize negative = maximize)\n",
        "    study_name=\"yolo_hyperparameter_optimization\"\n",
        ")\n",
        "\n",
        "n_trials = 5\n",
        "\n",
        "print(f\"Starting YOLO hyperparameter optimization with {n_trials} trials...\")\n",
        "print(\"Optimizing: Validation mAP@50 (higher is better)\")\n",
        "print(\"Hyperparameters being tuned:\")\n",
        "print(\"  - batch_size: [64, 128, 256]\")\n",
        "print(\"  - initial_lr: [0.001, 0.01] (log scale)\")\n",
        "print(\"  - final_lr: [0.01, 0.5]\")\n",
        "print()\n",
        "\n",
        "study.optimize(objective, n_trials=n_trials, n_jobs=1)\n",
        "\n",
        "print(f\"\\nOptimization complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Display Optimization Results\n",
        "\n",
        "Show the best parameters and visualize the optimization history.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Best Trial:\")\n",
        "print(f\"  Value (Validation mAP@50): {study.best_trial.value:.4f}\")\n",
        "print(f\"  Parameters:\")\n",
        "for key, value in study.best_trial.params.items():\n",
        "    print(f\"    {key}: {value}\")\n",
        "\n",
        "print(\"\\nAll Trials:\")\n",
        "trials_df = study.trials_dataframe()\n",
        "# Rename value column to mAP@50 for clarity\n",
        "trials_df['mAP@50'] = trials_df['value']\n",
        "display(trials_df[[\"number\", \"mAP@50\", \"params_batch_size\", \"params_initial_lr\", \"params_final_lr\", \"state\"]])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize Optimization History\n",
        "\n",
        "Plot the optimization progress over trials.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "trial_numbers = [t.number for t in study.trials if t.value is not None]\n",
        "trial_values = [t.value for t in study.trials if t.value is not None]\n",
        "trial_batch_sizes = [t.params[\"batch_size\"] for t in study.trials if t.value is not None]\n",
        "trial_initial_lrs = [t.params[\"initial_lr\"] for t in study.trials if t.value is not None]\n",
        "\n",
        "# Optimization history\n",
        "ax1.plot(trial_numbers, trial_values, marker='o', linewidth=2)\n",
        "ax1.set_xlabel('Trial Number')\n",
        "ax1.set_ylabel('Validation mAP@50')\n",
        "ax1.set_title('Optimization History')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Batch size vs mAP\n",
        "ax2.scatter(trial_batch_sizes, trial_values, s=100, alpha=0.6)\n",
        "ax2.set_xlabel('Batch Size')\n",
        "ax2.set_ylabel('Validation mAP@50')\n",
        "ax2.set_title('Batch Size vs mAP@50')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Initial LR vs mAP\n",
        "ax3.scatter(trial_initial_lrs, trial_values, s=100, alpha=0.6)\n",
        "ax3.set_xlabel('Initial Learning Rate')\n",
        "ax3.set_ylabel('Validation mAP@50')\n",
        "ax3.set_title('Initial LR vs mAP@50')\n",
        "ax3.set_xscale('log')\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Mark best trial on all plots\n",
        "best_idx = trial_values.index(max(trial_values))\n",
        "ax2.scatter([trial_batch_sizes[best_idx]], [trial_values[best_idx]], \n",
        "           s=200, color='red', marker='*', label='Best', zorder=5)\n",
        "ax2.legend()\n",
        "ax3.scatter([trial_initial_lrs[best_idx]], [trial_values[best_idx]], \n",
        "           s=200, color='red', marker='*', label='Best', zorder=5)\n",
        "ax3.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nRecommendation:\")\n",
        "print(f\"  Batch Size: {study.best_params['batch_size']}\")\n",
        "print(f\"  Initial LR: {study.best_params['initial_lr']:.5f}\")\n",
        "print(f\"  Final LR: {study.best_params['final_lr']:.3f}\")\n",
        "print(f\"  Best mAP@50: {study.best_trial.value:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
