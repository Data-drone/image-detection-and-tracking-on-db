{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Finetuning with Ultralytics YOLO Multi-GPU\n",
        "\n",
        "This notebook demonstrates fine-tuning the latest Ultralytics YOLO models (YOLO11/YOLOv8) on custom datasets in a distributed manner.\n",
        "\n",
        "**References:**\n",
        "- https://docs.ultralytics.com/modes/train/\n",
        "- https://docs.ultralytics.com/datasets/detect/\n",
        "\n",
        "**Prerequisites**\n",
        "- MLR 17.3 LTS - need numpy 2.z compatibility\n",
        "- Cluster with Multi-GPU\n",
        "- Cluster started with `scripts/init_script_ultralytics.sh` init script\n",
        "- **YOLO dataset already prepared** with:\n",
        "  - `data.yaml` config file in your dataset volume\n",
        "  - Images in `images/` directory\n",
        "  - Labels in `labels/` directory (YOLO format: class_id center_x center_y width height) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -U mlflow psutil nvidia-ml-py\n",
        "%restart_python\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Setup and Configure\n",
        "\n",
        "Initialize all variables needed for training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import mlflow\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Dataset configuration\n",
        "ds_catalog = 'brian_ml_dev'\n",
        "ds_schema = 'image_processing'\n",
        "dataset_volume = 'coco_dataset'\n",
        "\n",
        "# Paths\n",
        "dataset_path = f\"/Volumes/{ds_catalog}/{ds_schema}/{dataset_volume}\"\n",
        "config_path = f\"{dataset_path}/data.yaml\"  # YOLO config file (must exist)\n",
        "training_volume_path = f\"/local_disk0/ultralytics_logging_folder\"\n",
        "\n",
        "# MLflow\n",
        "mlflow_experiment = '/Users/brian.law@databricks.com/brian_yolo_training'\n",
        "\n",
        "# MLflow connectivity\n",
        "browser_host = spark.conf.get(\"spark.databricks.workspaceUrl\")\n",
        "db_host = f\"https://{browser_host}\"\n",
        "db_token = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
        "\n",
        "# YOLO model to start from (yolo11n.pt, yolo11s.pt, yolo11m.pt, yolo11l.pt, yolo11x.pt)\n",
        "YOLO_MODEL = 'yolo11n.pt'\n",
        "\n",
        "print(f\"Dataset location: {dataset_path}\")\n",
        "print(f\"Config file: {config_path}\")\n",
        "print(f\"Training outputs: {training_volume_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create Databricks widgets for hyperparameters\n",
        "dbutils.widgets.text(\"epochs\", \"2\", \"Epochs\")\n",
        "dbutils.widgets.text(\"batch_size\", \"128\", \"Batch Size\")\n",
        "dbutils.widgets.text(\"img_size\", \"640\", \"Image Size\")\n",
        "dbutils.widgets.text(\"initial_lr\", \"0.005\", \"Initial Learning Rate\")\n",
        "dbutils.widgets.text(\"final_lr\", \"0.1\", \"Final LR Factor\")\n",
        "dbutils.widgets.text(\"device_config\", \"[0,1]\", \"Device Config (e.g., [0,1])\")\n",
        "dbutils.widgets.text(\"run_name\", \"multi_gpu_run\", \"Run Name\")\n",
        "\n",
        "# Get hyperparameters from widgets\n",
        "EPOCHS = int(dbutils.widgets.get(\"epochs\"))\n",
        "BATCH_SIZE = int(dbutils.widgets.get(\"batch_size\"))\n",
        "IMG_SIZE = int(dbutils.widgets.get(\"img_size\"))\n",
        "initial_lr = float(dbutils.widgets.get(\"initial_lr\"))\n",
        "final_lr = float(dbutils.widgets.get(\"final_lr\"))\n",
        "device_config = eval(dbutils.widgets.get(\"device_config\"))  # Parse list from string\n",
        "run_name = dbutils.widgets.get(\"run_name\")\n",
        "\n",
        "print(\"Training Hyperparameters:\")\n",
        "print(f\"  Epochs: {EPOCHS}\")\n",
        "print(f\"  Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"  Image Size: {IMG_SIZE}\")\n",
        "print(f\"  Initial LR: {initial_lr}\")\n",
        "print(f\"  Final LR Factor: {final_lr}\")\n",
        "print(f\"  Device Config: {device_config}\")\n",
        "print(f\"  Run Name: {run_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Validate Dataset\n",
        "\n",
        "Verify that the YOLO dataset is properly configured and ready for training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import yaml\n",
        "from pathlib import Path\n",
        "\n",
        "# Verify config file exists\n",
        "if not Path(config_path).exists():\n",
        "    raise FileNotFoundError(f\"Config file not found: {config_path}\\n\"\n",
        "                          f\"Please run dataset preparation first.\")\n",
        "\n",
        "# Load and display config\n",
        "with open(config_path, 'r') as f:\n",
        "    yolo_config = yaml.safe_load(f)\n",
        "\n",
        "print(\"YOLO Dataset Configuration:\")\n",
        "print(f\"  Path: {yolo_config['path']}\")\n",
        "print(f\"  Train: {yolo_config['train']}\")\n",
        "print(f\"  Val: {yolo_config['val']}\")\n",
        "print(f\"  Classes: {yolo_config['nc']}\")\n",
        "print(f\"  Class names (first 10): {yolo_config['names'][:10]}...\")\n",
        "print(f\"\\n✓ Dataset configuration validated!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Multi-GPU Training with TorchDistributor\n",
        "\n",
        "For multi-GPU training on Databricks, we use `TorchDistributor` which properly manages distributed processes. This is required because Ultralytics' built-in `device=[0,1]` approach doesn't work in Databricks notebook environments.\n",
        "\n",
        "**How it works:**\n",
        "- TorchDistributor spawns one process per GPU\n",
        "- Each process runs the training function with its own `local_rank`\n",
        "- NCCL handles communication between GPUs\n",
        "- Only rank 0 handles MLflow logging\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Check GPU availability\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    gpu_count = torch.cuda.device_count()\n",
        "    print(f\"Available GPUs: {gpu_count}\")\n",
        "    for i in range(gpu_count):\n",
        "        print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
        "else:\n",
        "    raise RuntimeError(\"CUDA not available. This notebook requires GPU.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_single_gpu(run_id: str):\n",
        "    \"\"\"\n",
        "    Training function that runs on each GPU process.\n",
        "    TorchDistributor will spawn this function on each GPU.\n",
        "    Includes MLflow dataset and model logging (rank 0 only).\n",
        "    \"\"\"\n",
        "    import os\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import torch.distributed as dist\n",
        "    from torchvision.ops import nms\n",
        "    from ultralytics import YOLO\n",
        "    from ultralytics import settings\n",
        "    import mlflow\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    from mlflow.models.signature import ModelSignature\n",
        "    from mlflow.types import Schema, TensorSpec\n",
        "\n",
        "    # Set Databricks credentials\n",
        "    os.environ['DATABRICKS_HOST'] = db_host\n",
        "    os.environ['DATABRICKS_TOKEN'] = db_token\n",
        "    \n",
        "    # Get distributed training context\n",
        "    rank = int(os.environ.get('RANK', 0))\n",
        "    local_rank = int(os.environ.get('LOCAL_RANK', 0))\n",
        "    world_size = int(os.environ.get('WORLD_SIZE', 1))\n",
        "    \n",
        "    print(f\"[Rank {rank}] Process started - local_rank: {local_rank}, world_size: {world_size}\")\n",
        "    print(f\"[Rank {rank}] CUDA available: {torch.cuda.is_available()}\")\n",
        "    \n",
        "    # NCCL configuration for cloud environments\n",
        "    os.environ['NCCL_IB_DISABLE'] = '1'\n",
        "    os.environ['NCCL_P2P_DISABLE'] = '1'\n",
        "    \n",
        "    # Initialize distributed process group if not already initialized\n",
        "    if world_size > 1 and not dist.is_initialized():\n",
        "        print(f\"[Rank {rank}] Initializing process group...\")\n",
        "        dist.init_process_group(\n",
        "            backend='nccl',\n",
        "            init_method='env://',\n",
        "            world_size=world_size,\n",
        "            rank=rank\n",
        "        )\n",
        "        print(f\"[Rank {rank}] Process group initialized\")\n",
        "    \n",
        "    # Set CUDA device for this process\n",
        "    torch.cuda.set_device(local_rank)\n",
        "    \n",
        "    # MLflow setup - ONLY on rank 0\n",
        "    if rank == 0:\n",
        "        settings.update({\"mlflow\": True})\n",
        "        os.environ['MLFLOW_EXPERIMENT_NAME'] = mlflow_experiment\n",
        "        os.environ['MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING'] = \"true\"\n",
        "        os.environ['MLFLOW_RUN_ID'] = run_id\n",
        "        print(f\"[Rank 0] MLflow configured with run_id: {run_id}\")\n",
        "    else:\n",
        "        # Disable MLflow on non-rank-0 processes\n",
        "        settings.update({\"mlflow\": False})\n",
        "        os.environ.pop('MLFLOW_EXPERIMENT_NAME', None)\n",
        "        os.environ.pop('MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING', None)\n",
        "        os.environ.pop('MLFLOW_RUN_ID', None)\n",
        "        print(f\"[Rank {rank}] MLflow disabled for this process\")\n",
        "    \n",
        "    # Log dataset reference (rank 0 only)\n",
        "    if rank == 0:\n",
        "        try:\n",
        "            print(f\"[Rank 0] Logging dataset reference...\")\n",
        "            dataset_info = pd.DataFrame([{\n",
        "                'dataset_path': dataset_path,\n",
        "                'config_file': config_path,\n",
        "                'num_classes': yolo_config['nc'],\n",
        "                'class_names': ','.join(yolo_config['names'][:10]) + '...',\n",
        "            }])\n",
        "            \n",
        "            dataset = mlflow.data.from_pandas(\n",
        "                dataset_info,\n",
        "                source=dataset_path,\n",
        "                name=f\"{ds_catalog}.{ds_schema}.{dataset_volume}\",\n",
        "            )\n",
        "            \n",
        "            mlflow.log_input(dataset, context=\"training\")\n",
        "            print(f\"[Rank 0] ✓ Dataset logged - {yolo_config['nc']} classes\")\n",
        "        except Exception as e:\n",
        "            print(f\"[Rank 0] Warning: Could not log dataset - {e}\")\n",
        "    \n",
        "    # Load model\n",
        "    print(f\"[Rank {rank}] Loading model: {YOLO_MODEL}\")\n",
        "    model = YOLO(YOLO_MODEL)\n",
        "    \n",
        "    # Train - each process trains on its local GPU\n",
        "    print(f\"[Rank {rank}] Starting training on GPU {local_rank}...\")\n",
        "    results = model.train(\n",
        "        data=config_path,\n",
        "        epochs=EPOCHS,\n",
        "        batch=BATCH_SIZE,\n",
        "        lr0=initial_lr,\n",
        "        lrf=final_lr,\n",
        "        imgsz=IMG_SIZE,\n",
        "        name=run_name,\n",
        "        project=training_volume_path,\n",
        "        device=local_rank,\n",
        "        workers=4,\n",
        "        patience=50,\n",
        "        save=True,\n",
        "        save_period=5,\n",
        "        verbose=(rank == 0),\n",
        "        exist_ok=True\n",
        "    )\n",
        "    \n",
        "    # Log wrapped model (rank 0 only)\n",
        "    if rank == 0:\n",
        "        try:\n",
        "            print(f\"[Rank 0] Loading best model for MLflow logging...\")\n",
        "            \n",
        "            # Define YoloDetWrapper inline\n",
        "            class YoloDetWrapper(nn.Module):\n",
        "                def __init__(self, base: nn.Module, conf_thres=0.25, iou_thres=0.5, max_det=300):\n",
        "                    super().__init__()\n",
        "                    self.base = base.eval()\n",
        "                    self.conf_thres, self.iou_thres, self.max_det = conf_thres, iou_thres, max_det\n",
        "\n",
        "                @staticmethod\n",
        "                def xywh_to_xyxy(b):\n",
        "                    x,y,w,h = b.unbind(-1)\n",
        "                    x1 = x - w/2; y1 = y - h/2; x2 = x + w/2; y2 = y + h/2\n",
        "                    return torch.stack([x1,y1,x2,y2], dim=-1)\n",
        "\n",
        "                def forward(self, x):\n",
        "                    with torch.no_grad():\n",
        "                        out = self.base(x)\n",
        "                        if isinstance(out, (list, tuple)): out = out[0]\n",
        "                        if out.dim() == 3 and out.shape[1] < out.shape[2]:\n",
        "                            out = out.permute(0, 2, 1).contiguous()\n",
        "                        \n",
        "                        boxes_xywh = out[..., :4]\n",
        "                        obj = out[..., 4:5].sigmoid()\n",
        "                        cls = out[..., 5:].sigmoid()\n",
        "                        conf, cls_id = (obj * cls).max(-1)\n",
        "                        boxes = self.xywh_to_xyxy(boxes_xywh)\n",
        "\n",
        "                        N, A = conf.shape\n",
        "                        K = self.max_det\n",
        "                        out_pad = x.new_full((N, K, 6), -1.0)\n",
        "\n",
        "                        for i in range(N):\n",
        "                            mask = conf[i] >= self.conf_thres\n",
        "                            if mask.sum() == 0: continue\n",
        "                            b = boxes[i][mask]\n",
        "                            s = conf[i][mask]\n",
        "                            c = cls_id[i][mask].float()\n",
        "                            keep = nms(b, s, self.iou_thres)[:K]\n",
        "                            k = keep.numel()\n",
        "                            if k == 0: continue\n",
        "                            out_pad[i, :k, :4] = b[keep]\n",
        "                            out_pad[i, :k, 4]  = s[keep]\n",
        "                            out_pad[i, :k, 5]  = c[keep]\n",
        "                        return out_pad\n",
        "            \n",
        "            # Load and wrap best model\n",
        "            best_model_path = f\"{training_volume_path}/{run_name}/weights/best.pt\"\n",
        "            best_model_raw = YOLO(best_model_path).model\n",
        "            wrapped_model = YoloDetWrapper(best_model_raw, conf_thres=0.25, iou_thres=0.5, max_det=300)\n",
        "            \n",
        "            # Create model signature\n",
        "            input_schema = Schema([\n",
        "                TensorSpec(type=np.dtype(np.float32), shape=(-1, 3, IMG_SIZE, IMG_SIZE), name=\"images\")\n",
        "            ])\n",
        "            output_schema = Schema([\n",
        "                TensorSpec(type=np.dtype(np.float32), shape=(-1, None, 6), name=\"detections\")\n",
        "            ])\n",
        "            signature = ModelSignature(inputs=input_schema, outputs=output_schema)\n",
        "            \n",
        "            # Log model to MLflow\n",
        "            print(f\"[Rank 0] Logging wrapped model to MLflow...\")\n",
        "            mlflow.pytorch.log_model(\n",
        "                pytorch_model=wrapped_model,\n",
        "                artifact_path=\"best_model\",\n",
        "                signature=signature,\n",
        "                #registered_model_name=f\"{ds_catalog}.{ds_schema}.yolo_model\"  # Uncomment to register\n",
        "            )\n",
        "            print(f\"[Rank 0] ✓ Model logged successfully\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"[Rank 0] Warning: Could not log model - {e}\")\n",
        "    \n",
        "    print(f\"[Rank {rank}] Training finished, cleaning up...\")\n",
        "    \n",
        "    # Cleanup distributed process group\n",
        "    if world_size > 1 and dist.is_initialized():\n",
        "        dist.barrier()  # Ensure all processes finish\n",
        "        dist.destroy_process_group()\n",
        "        print(f\"[Rank {rank}] Process group destroyed\")\n",
        "    \n",
        "    # Force cleanup\n",
        "    import gc\n",
        "    gc.collect()\n",
        "    \n",
        "    if rank == 0:\n",
        "        print(\"[Rank 0] Training complete!\")\n",
        "        return results\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.ml.torch.distributor import TorchDistributor\n",
        "import time\n",
        "\n",
        "# Set MLflow experiment\n",
        "mlflow.set_experiment(mlflow_experiment)\n",
        "\n",
        "# Create TorchDistributor and run training\n",
        "num_processes = len(device_config) if isinstance(device_config, list) else 1\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"Starting distributed training with {num_processes} GPUs\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "# Start MLflow run with system metrics logging\n",
        "with mlflow.start_run(run_name=run_name, log_system_metrics=True) as run:\n",
        "    active_run_id = run.info.run_id\n",
        "    print(f\"MLflow Run ID: {active_run_id}\\n\")\n",
        "    \n",
        "    # Log hyperparameters upfront\n",
        "    mlflow.log_params({\n",
        "        'model': YOLO_MODEL,\n",
        "        'epochs': EPOCHS,\n",
        "        'batch_size': BATCH_SIZE,\n",
        "        'img_size': IMG_SIZE,\n",
        "        'initial_lr': initial_lr,\n",
        "        'final_lr': final_lr,\n",
        "        'num_gpus': num_processes,\n",
        "        'device_config': str(device_config),\n",
        "        'run_name': run_name,\n",
        "        'dataset_path': dataset_path,\n",
        "    })\n",
        "    \n",
        "    # Create distributor\n",
        "    distributor = TorchDistributor(\n",
        "        num_processes=num_processes,\n",
        "        local_mode=True,  # Single node multi-GPU\n",
        "        use_gpu=True\n",
        "    )\n",
        "    \n",
        "    # Run distributed training\n",
        "    output = distributor.run(train_single_gpu, active_run_id)\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"Training complete! All MLflow logging finished.\")\n",
        "print(f\"View results at: {mlflow_experiment}\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "# Small delay to ensure all background processes fully exit\n",
        "time.sleep(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training Complete!\n",
        "\n",
        "The training function above includes all MLflow integration:\n",
        "\n",
        "**What's Logged:**\n",
        "- ✅ **Hyperparameters** - Model config, training settings, dataset info\n",
        "- ✅ **Dataset Lineage** - Dataset reference with class information  \n",
        "- ✅ **Training Metrics** - Ultralytics built-in MLflow callback logs metrics automatically\n",
        "- ✅ **Wrapped Model** - Deployment-ready PyTorch model with proper signature\n",
        "- ✅ **System Metrics** - GPU/CPU/memory usage during training\n",
        "\n",
        "**Next Steps:**\n",
        "- View results in MLflow UI at the experiment path above\n",
        "- Uncomment `registered_model_name` in the training function to register the model to Unity Catalog\n",
        "- Use the logged model artifact for deployment or further evaluation"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
